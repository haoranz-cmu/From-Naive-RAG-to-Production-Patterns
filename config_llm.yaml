# LLM Configuration File
# 这个文件包含所有LLM相关的配置

# 默认模型设置
models:
  default: "deepseek/deepseek-chat-v3.1:free"  # default model, deepseek v3.1 free version
  fallback: "qwen/qwen3-235b-a22b:free"  # fallback model, Qwen3 235B A22B (free)

# default generation parameters
generation:
  max_tokens: 150
  temperature: 0.7
  top_p: 1.0
  frequency_penalty: 0.0
  presence_penalty: 0.0

# 提示策略设置
prompting:
  default_strategy: "basic"
  available_strategies:
    - "basic"
    - "cot"
    - "persona"
    - "instruction"
  
  # 策略特定设置
  strategies:
    basic:
      max_tokens: 150
      temperature: 0.7
    cot:
      max_tokens: 200
      temperature: 0.5
    persona:
      max_tokens: 150
      temperature: 0.7
    instruction:
      max_tokens: 150
      temperature: 0.3

# API设置
api:
  timeout: 30  # 请求超时时间（秒）
  retry_attempts: 3  # 重试次数
  retry_delay: 1  # 重试延迟（秒）

# 日志设置
logging:
  level: "INFO"
  log_requests: true
  log_responses: false
